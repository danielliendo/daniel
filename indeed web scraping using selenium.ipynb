{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "def SaveOnFile(FileName, title, location, company,salary, sponsored, ratings,DatePost,job_desc, remarks):\n",
    "    with open(FileName + '.csv', 'a',newline='') as jobsearch_file:\n",
    "        jobsearch_file = csv.writer(jobsearch_file)\n",
    "        jobsearch_file.writerow([title, location, company,salary, sponsored, ratings,DatePost,job_desc, remarks])\n",
    "\n",
    "def SaveOnFileFails(FileName, title, location, company, RowFail):\n",
    "    with open(FileName + '.csv', 'a',newline='') as jobsearch_file:\n",
    "        jobsearch_file = csv.writer(jobsearch_file)\n",
    "        jobsearch_file.writerow([title, location, company,RowFail])\n",
    "\n",
    "        \n",
    "#, delimiter=',', quotechar='\"', quoting=csv.QUOTE_ALL\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-6-ea2cf43bd825>:15: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome('./chromedriver')\n",
      "<ipython-input-6-ea2cf43bd825>:48: DeprecationWarning: find_elements_by_* commands are deprecated. Please use find_elements() instead\n",
      "  all_jobs=driver.find_elements_by_class_name('result')\n",
      "C:\\Users\\danie\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webelement.py:463: UserWarning: find_elements_by_* commands are deprecated. Please use find_elements() instead\n",
      "  warnings.warn(\"find_elements_by_* commands are deprecated. Please use find_elements() instead\")\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-ea2cf43bd825>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     88\u001b[0m                 \u001b[0mDatePost\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 90\u001b[1;33m             \u001b[0msum_div\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_elements_by_class_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'summary'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     91\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "\n",
    "FastRun = 0   #(0 or 1)\n",
    "if FastRun == 1:\n",
    "    sleeptime = 1\n",
    "else:\n",
    "    sleeptime = 4\n",
    "\n",
    "driver = webdriver.Chrome('./chromedriver')\n",
    "def RemarksValue (RemarkIndex, Type):\n",
    "    try:\n",
    "        if Type == 1:\n",
    "            return driver.find_element_by_xpath('//*[@id=\"vjs-tab-job\"]/div[1]/div['+str(RemarkIndex)+']/span[2]').text\n",
    "        else:\n",
    "            return driver.find_element_by_xpath('/html/body/div[1]/div[2]/div[3]/div/div/div[1]/div[1]/div[3]/div[1]/div['+str(RemarkIndex)+']/span').text\n",
    "    except:\n",
    "        return 0\n",
    "\n",
    "dataframe = pd.DataFrame(columns=['Title','Location','Company','Salary','Sponsored','Ratings','DatePost','Description', 'Remarks'])\n",
    "fails = pd.DataFrame(columns=['Title','Location','Company','RowFail'])\n",
    "\n",
    "DataFileName = 'Data'\n",
    "FailFileName = 'Fails'\n",
    "\n",
    "dataframe.to_csv(DataFileName + '.csv',index=False)\n",
    "dataframe.to_csv(FailFileName + '.csv',index=False)\n",
    "\n",
    "\n",
    "Extension = ''\n",
    "for i in range(0,600,1):\n",
    "    \n",
    "    if i >= 1:\n",
    "        Extension = '&filter=0'    \n",
    "    \n",
    "    for y in range(0,1000,10):\n",
    "        \n",
    "        driver.get('https://ca.indeed.com/jobs?q=data+science&l=Canada'+str(Extension)+'&start='+str(y))\n",
    "        driver.implicitly_wait(4)\n",
    "        #act = ActionChains(driver)\n",
    "        #act.send_keys(Keys.END).perform()\n",
    "        \n",
    "        all_jobs=driver.find_elements_by_class_name('result')\n",
    "        \n",
    "        for job in all_jobs:\n",
    "            try:\n",
    "                result_html = job.get_attribute('innerHTML')\n",
    "                soup = BeautifulSoup(result_html,'html.parser')\n",
    "            except:\n",
    "                driver.switch_to.window(driver.window_handles[1])\n",
    "                driver.close()\n",
    "                driver.switch_to.window(driver.window_handles[0])\n",
    "                time.sleep(sleeptime)\n",
    "                result_html = job.get_attribute('innerHTML')\n",
    "                soup = BeautifulSoup(result_html,'html.parser')                    \n",
    "            try:\n",
    "                title = soup.find('a', class_='jobtitle').text.replace('\\n','')\n",
    "            except:\n",
    "                title = None\n",
    "            try:\n",
    "                location = soup.find(class_='location').text\n",
    "            except:\n",
    "                location = None\n",
    "            try:\n",
    "                company = soup.find(class_='company').text.replace('\\n','').strip()\n",
    "            except:\n",
    "                company = None\n",
    "            try:\n",
    "                salary = soup.find(class_='salary').text.replace('\\n','').strip()\n",
    "            except:\n",
    "                salary = None\n",
    "            try:\n",
    "                sponsored = soup.find(class_='sponsoredGray').text\n",
    "            except:\n",
    "                sponsored = 'Organic'\n",
    "            try:\n",
    "                ratings = soup.find(class_='ratingsContent').text.replace('\\n','')\n",
    "            except:\n",
    "                ratings = None\n",
    "            try:\n",
    "                DatePost = soup.find(class_='date').text\n",
    "            except:\n",
    "                DatePost = None\n",
    "            \n",
    "            sum_div = job.find_elements_by_class_name('summary')[0]\n",
    "            \n",
    "            try:\n",
    "                time.sleep(sleeptime)\n",
    "                if FastRun == 0:\n",
    "                    sum_div.click()\n",
    "                time.sleep(sleeptime) \n",
    "            except:                    \n",
    "                act = ActionChains(driver)\n",
    "                act.send_keys(Keys.ESCAPE).perform()\n",
    "                time.sleep(sleeptime) \n",
    "                sum_div.click()\n",
    "                time.sleep(sleeptime)             \n",
    "            if FastRun == 0:\n",
    "                try:\n",
    "                    job_desc = driver.find_element_by_id('vjs-desc').text\n",
    "                    j=1\n",
    "                    remark_list = []\n",
    "                    while RemarksValue(j,1) != 0:\n",
    "                        remark_list.append(RemarksValue(j,1))\n",
    "                        j += 1\n",
    "                    remarks = remark_list\n",
    "                except:\n",
    "                    try:\n",
    "                        driver.switch_to.window(driver.window_handles[1])\n",
    "                        job_desc = driver.find_element_by_id('jobDescriptionText').text\n",
    "                        j=1\n",
    "                        remark_list = []\n",
    "                        while RemarksValue(j,2) != 0:\n",
    "                            remark_list.append(RemarksValue(j,2))\n",
    "                            j += 1\n",
    "                        remarks = remark_list                \n",
    "\n",
    "                        driver.close()\n",
    "                        driver.switch_to.window(driver.window_handles[0])\n",
    "                    except:\n",
    "                        job_desc = \"\"\n",
    "                        remarks = \"\"\n",
    "                        rowfail = dataframe.shape[0]\n",
    "                        fails = fails.append(({'Title':title,'Location':location,'Company':company, 'RowFail':rowfail}),ignore_index=True)\n",
    "                        SaveOnFileFails(FailFileName, title, location, company,rowfail)\n",
    "                        driver.switch_to.window(driver.window_handles[0])\n",
    "            else:                \n",
    "                job_desc = \"\"\n",
    "                remarks = \"\"            \n",
    "            dataframe = dataframe.append({'Title':title,'Location':location,'Company':company,'Salary':salary,\n",
    "                                          'Sponsored':sponsored,'Ratings':ratings,'DatePost':DatePost,\n",
    "                                          'Description':job_desc, 'Remarks':remarks},ignore_index=True)\n",
    "            try:\n",
    "                SaveOnFile(DataFileName, title, location, company,salary, sponsored, ratings,DatePost,job_desc, remarks)\n",
    "            except:\n",
    "                rowfail = dataframe.shape[0]\n",
    "                fails = fails.append(({'Title':title,'Location':location,'Company':company, 'RowFail':rowfail}),ignore_index=True)                    \n",
    "                SaveOnFileFails(FailFileName, title, location, company,rowfail)\n",
    "    \n",
    "dataframe.to_csv(DataFileName + 'canada.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
